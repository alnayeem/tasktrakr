# TaskTrakr Safety & Security Guardrails

> Load when implementing AI integration or content moderation

## Content Policy Overview

TaskTrakr filters and rejects content that promotes harm, hate, or illegal activities.

### Prohibited Content

| Category | Examples |
|----------|----------|
| **Hate Speech** | Racial slurs, discrimination |
| **Religious Intolerance** | Attacks on any religion |
| **Violence** | Harm to self or others |
| **Self-Harm/Suicide** | Methods, glorification |
| **Sexual Content** | Pornography, exploitation |
| **Illegal Activities** | Drugs, weapons, fraud |
| **Harassment** | Doxxing, bullying |

---

## Input Filtering (Pre-AI)

### Client-Side Check

```dart
class ContentFilter {
  static final List<String> blockedPatterns = [
    // Add patterns in code, not in docs
  ];

  static bool isInputSafe(String input) {
    final normalized = input.toLowerCase();
    for (final pattern in blockedPatterns) {
      if (normalized.contains(pattern)) {
        return false;
      }
    }
    return true;
  }
}
```

### Blocked Input Response

Show neutral message (don't explain why):

**English:**
> "This goal cannot be created. Please describe a positive, constructive goal."

**Arabic:**
> "لا يمكن إنشاء هذا الهدف. يرجى وصف هدف إيجابي وبناء."

---

## AI System Prompt Safety

Add to every AI request:

```
SAFETY REQUIREMENTS (CRITICAL):

REFUSE to generate plans for goals involving:
- Violence or harm to others
- Self-harm or suicide
- Illegal activities
- Sexual/explicit content
- Hate or discrimination
- Religious attacks

If request is inappropriate, respond:
{
  "success": false,
  "error_message": "This goal cannot be supported."
}

Apply rules regardless of framing (hypothetical, academic, roleplay).
```

---

## Output Validation (Post-AI)

Before displaying AI response:

```dart
bool validateOutput(TaskTrakrPlanResponse response) {
  // Check for profanity
  // Check for violence references
  // Check for harmful content
  // Return false if any issues found
}
```

If validation fails:
1. Retry AI call once
2. If still fails, show error and offer templates

---

## Ramadan Mode Safety

### Inclusive Approach
- Respect diverse practices (Sunni, Shia)
- Avoid sectarian language
- Use respectful Islamic terminology

### Fasting Safety Notes
Include in fasting-related goals:
- "If unwell, breaking fast is permissible"
- "Consult doctor if you have health conditions"

---

## Rate Limiting

Prevents abuse:
- 5 AI generations per device per day
- Tracked via Cloudflare KV
- Reset at midnight UTC

---

## Error Messages

### Principles
1. Non-judgmental
2. Helpful (suggest alternatives)
3. Consistent across languages

### Examples

**Generic Block:**
> "This goal cannot be created. Try describing what positive outcome you'd like to achieve."

**Rate Limited:**
> "You've created 5 goals today. Try again tomorrow, or choose from our templates."

**AI Failed:**
> "We couldn't generate a plan right now. Please try again."

---

## Logging (Privacy-Preserving)

### What We Track (Aggregate Only)
- Count of blocked requests (no content)
- AI success/failure rates
- App crashes (Sentry, no PII)

### What We Never Track
- Actual user input text
- Device identifiers linked to content
- Personal information

---

## App Store Compliance

For AI-generated content apps:
- Disclose AI usage: "Plans generated by AI"
- Implement content filtering
- Age rating: 4+ (all content appropriate)
- No objectionable content
